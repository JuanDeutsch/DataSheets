{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  5.19615242, 10.39230485],\n",
       "       [ 5.19615242,  0.        ,  5.19615242],\n",
       "       [10.39230485,  5.19615242,  0.        ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDistances(A):\n",
    "    if not isinstance(A, np.ndarray):\n",
    "        A = A.values.reshape(-1, A.shape[-1])\n",
    "\n",
    "    n = A.shape[0]\n",
    "    Distance = np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            Distance[i,j] = np.linalg.norm(A[i] - A[j])\n",
    "            Distance[j,i] = Distance[i,j]\n",
    "    return Distance\n",
    "\n",
    "getDistances(np.array([[1,2,3],[4,5,6],[7,8,9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getW(D,U,V):\n",
    "    weight = 0\n",
    "    for i in U:\n",
    "        for j in V:\n",
    "            weight += D[i,j]\n",
    "    return weight\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWIn(D,C):\n",
    "    Win = 0\n",
    "    clusters = set(C)\n",
    "    for cluster in clusters:\n",
    "        indices = [i for i, x in enumerate(C) if x == cluster]\n",
    "        Win += getW(D, indices, indices)\n",
    "    return round(Win/2, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWOut(D,C):\n",
    "    Wout = 0\n",
    "    clusters = set(C)\n",
    "    for cluster in clusters:\n",
    "        indices = [i for i, x in enumerate(C) if x == cluster]\n",
    "        for i in indices:\n",
    "            for j in range(len(D)):\n",
    "                if j in indices:\n",
    "                    continue\n",
    "                Wout += D[i,j]\n",
    "    return round(Wout/2,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNIn(C):\n",
    "    Nin = 0\n",
    "    clusters = set(C)\n",
    "    for cluster in clusters:\n",
    "        n = [i for i, x in enumerate(C) if x == cluster]\n",
    "        Nin += len(n) * (len(n)-1)/2\n",
    "    return Nin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNOut(C):\n",
    "    n = len(C)\n",
    "    Nout = (n*(n-1)/2) - getNIn(C)\n",
    "    return Nout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "\n",
      "Test Weight Measures\n",
      "------------------\n",
      "W: ok\n",
      "WIn: ok\n",
      "WOut: ok\n",
      "NIn: ok\n",
      "NOut: ok\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd_test\n",
    "import numpy as np_test\n",
    "dfIrisTest = pd_test.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "A_Iris_Test = dfIrisTest[dfIrisTest.columns[:4]].astype(float)\n",
    "C_Iris_Test = dfIrisTest[dfIrisTest.columns[4]]\n",
    "print(type(A_Iris_Test))\n",
    "D_Iris_Test = getDistances(A_Iris_Test)\n",
    "C1 = np.where(C_Iris_Test == 'setosa')[0]\n",
    "C2 = np.where(C_Iris_Test == 'versicolor')[0]\n",
    "C3 = np.where(C_Iris_Test == 'virginica')[0]\n",
    "CList = [C1, C2, C3]\n",
    "\n",
    "print (\"\\nTest Weight Measures\\n------------------\")\n",
    "expectedW = {\n",
    "    (0,1): 8246,\n",
    "    (0,2): 12056,\n",
    "    (1,2): 4606\n",
    "}\n",
    "wSummary = \"W: \"\n",
    "wFailed = False\n",
    "for i in range(3):\n",
    "    for j in range(i):\n",
    "        p1 = (i,j)\n",
    "        p2 = (j,i)\n",
    "        W1 = np_test.round(getW(D_Iris_Test, CList[i], CList[j]))\n",
    "        W2 = np_test.round(getW(D_Iris_Test, CList[j], CList[i]))\n",
    "        if W1 != W2:\n",
    "            if not wFailed:\n",
    "                wSummary += \"failed\"\n",
    "            wSummary += \"\\n\\tasymmetry of W: \" + str(W1) + \" != \" + str(W2)\n",
    "            wFailed = True\n",
    "        \n",
    "        if W1 != expectedW[p2]:\n",
    "            if not wFailed:\n",
    "                wSummary += \"failed\"\n",
    "            wSummary += \"\\n\\tunexpected value of W: \" + str(W1) + \" instead of expected \" + str(expectedW[p2])\n",
    "            wFailed = True\n",
    "if not wFailed:\n",
    "    wSummary += \"ok\"\n",
    "print(wSummary)\n",
    "expectedWIn = 3518\n",
    "expectedWOut = 24908\n",
    "expectedNIn = 3675\n",
    "expectedNOut = 7500\n",
    "print(\"WIn:\", \"ok\" if np_test.abs(np_test.round(getWIn(D_Iris_Test, C_Iris_Test)) - expectedWIn) < 2 else \"failed\")\n",
    "print(\"WOut:\", \"ok\" if np_test.abs(np_test.round(getWOut(D_Iris_Test, C_Iris_Test)) - expectedWOut) < 2 else \"failed\")\n",
    "print(\"NIn:\", \"ok\" if getNIn(C_Iris_Test) == 3675 else \"failed\")\n",
    "print(\"NOut:\", \"ok\" if getNOut(C_Iris_Test) == 7500 else \"failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def getBetaCV(A, C):\n",
    "    D = getDistances(A)\n",
    "\n",
    "    \n",
    "    W_in = getWIn(D, C)\n",
    "    W_out = getWOut(D, C)\n",
    "    N_in = getNIn(C)\n",
    "    N_out = getNOut(C)\n",
    "    \n",
    "    beta_cv = (W_in / N_in) / (W_out / N_out)\n",
    "    \n",
    "    return beta_cv\n",
    "\n",
    "def getCIndex(A,C):\n",
    "    \n",
    "    D = getDistances(A)\n",
    "    Nin = getNIn(C)\n",
    "    Win = getWIn(D, C)\n",
    "    Wflat = np.ravel(D)\n",
    "    Wmin = np.sum(np.partition(Wflat, int(Nin))[:int(Nin)])\n",
    "    Wmax = np.sum(np.partition(Wflat, -int(Nin))[-int(Nin):])\n",
    "    \n",
    "    CIndex = ((Win - Wmin)/(Wmax - Wmin))/2\n",
    "    return CIndex\n",
    "\n",
    "\n",
    "def getNormalizedCut(A, C):\n",
    "    normalized_cut = 0\n",
    "\n",
    "    D = getDistances(A)\n",
    "\n",
    "    clusters = list(set(C))\n",
    "    cluster_indices = {cluster: [i for i, label in enumerate(C) if label == cluster] for cluster in clusters}\n",
    "\n",
    "    for cluster_i in clusters:\n",
    "        w_other_clusters = 0\n",
    "        vol_cluster_i = 0\n",
    "        for cluster_j in clusters:\n",
    "            weight = getW(D, U=cluster_indices[cluster_i], V=cluster_indices[cluster_j])\n",
    "            if cluster_i != cluster_j:\n",
    "                w_other_clusters += weight\n",
    "            vol_cluster_i += weight\n",
    "\n",
    "        normalized_cut += w_other_clusters / vol_cluster_i\n",
    "\n",
    "    return normalized_cut\n",
    "\n",
    "def getDunn(A, C):\n",
    "  \n",
    "    D = getDistances(A)  \n",
    "\n",
    "    n = len(C)\n",
    "\n",
    "    mask = np.zeros_like(D, dtype=bool)\n",
    "    \n",
    "    np.fill_diagonal(mask, True)  \n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            mask[i, j] = mask[j, i] = C[i] == C[j]  \n",
    "\n",
    "    w_in = D[mask]\n",
    "    w_max_in = w_in.max()\n",
    "\n",
    "    w_out = D[~mask]  \n",
    "    w_min_out = np.min(w_out[w_out != 0])  \n",
    "\n",
    "    return w_min_out / w_max_in\n",
    "\n",
    "def getDaviesBouldin(A, C):\n",
    "    A = np.array(A)\n",
    "\n",
    "    indexesClusters = list(set(C))\n",
    "    k = len(indexesClusters)\n",
    "    dataCluster = []\n",
    "    centroidCluster = []\n",
    "    varianceCluster = []\n",
    "    Rij = []\n",
    "    DBIndex = 0\n",
    "\n",
    "    for i, indexer in enumerate(indexesClusters):\n",
    "        \n",
    "        dataCluster.append(A[C == indexer]) #Datos por cluster para la media\n",
    "        centroidCluster.append(np.mean(dataCluster[i], axis=0)) #Centroide de cada cluster\n",
    "        varI=np.linalg.norm(np.std(dataCluster[i],axis=0))\n",
    "        varianceCluster.append(varI) #Varianza de cada cluster\n",
    "\n",
    "    DBIndex = 0\n",
    "    for i in range(k):\n",
    "        Rij = []\n",
    "        for j in range(k):\n",
    "            if i != j:\n",
    "                perCluster = (varianceCluster[i] + varianceCluster[j]) / np.linalg.norm(centroidCluster[i] - centroidCluster[j])\n",
    "                Rij.append(perCluster)\n",
    "        DBIndex += max(Rij)\n",
    "\n",
    "    DBIndex /= k\n",
    "    return DBIndex\n",
    "\n",
    "def getSilhouette(A, C):\n",
    "    A = np.array(A)\n",
    "    indexesClusters = list(set(C))\n",
    "    k = len(indexesClusters)\n",
    "    dataCluster = []\n",
    "\n",
    "    for i, indexer in enumerate(indexesClusters):\n",
    "        dataCluster.append(A[C == indexer])\n",
    "    \n",
    "    silhouette = 0\n",
    "    for i in range(k):\n",
    "        for index_point_ClusterI in range(len(dataCluster[i])):\n",
    "            b = np.min([np.linalg.norm(dataCluster[i][index_point_ClusterI] - dataCluster[l], axis=1).mean() for l in range(k) if l != i])\n",
    "            a = np.linalg.norm(dataCluster[i][index_point_ClusterI]-dataCluster[i], axis=1)\n",
    "            a = np.sum(a) / (len(dataCluster[i]) - 1)\n",
    "            silhouette += (b - a) / max(a, b)\n",
    "    silhouette /= len(A)\n",
    "    return silhouette\n",
    "\n",
    "A_Iris_Test = dfIrisTest[dfIrisTest.columns[:4]].astype(float)\n",
    "C_Iris_Test = dfIrisTest[dfIrisTest.columns[4]]\n",
    "getSilhouette(A_Iris_Test, C_Iris_Test)\n",
    "\n",
    "def getMetric(A, C, metric):\n",
    "    if metric == \"cindex\":\n",
    "        return getCIndex(A, C)\n",
    "    elif metric == \"beta\":\n",
    "        return getBetaCV(A, C)\n",
    "    elif metric == \"nc\":\n",
    "        return getNormalizedCut(A, C)\n",
    "    elif metric == \"db\":\n",
    "        return getDaviesBouldin(A, C)\n",
    "    elif metric == \"sil\":\n",
    "        return getSilhouette(A, C)\n",
    "    elif metric == \"dunn\":\n",
    "        return getDunn(A, C)\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0             5.1          3.5           1.4          0.2\n",
       "1             4.9          3.0           1.4          0.2\n",
       "2             4.7          3.2           1.3          0.2\n",
       "3             4.6          3.1           1.5          0.2\n",
       "4             5.0          3.6           1.4          0.2\n",
       "..            ...          ...           ...          ...\n",
       "145           6.7          3.0           5.2          2.3\n",
       "146           6.3          2.5           5.0          1.9\n",
       "147           6.5          3.0           5.2          2.0\n",
       "148           6.2          3.4           5.4          2.3\n",
       "149           5.9          3.0           5.1          1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics\n",
      "------------------\n",
      "beta:\t ok\n",
      "cindex:\t ok\n",
      "nc:\t ok\n",
      "dunn:\t ok\n",
      "db:\t ok\n",
      "sil:\t ok\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd_test\n",
    "import numpy as np_test\n",
    "dfIrisTest = pd_test.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\n",
    "A_Iris_Test = dfIrisTest[dfIrisTest.columns[:4]].astype(float)\n",
    "C_Iris_Test = dfIrisTest[dfIrisTest.columns[4]]\n",
    "D_Iris_Test = getDistances(A_Iris_Test)\n",
    "display(A_Iris_Test)\n",
    "\n",
    "# Test metrics\n",
    "print (\"\\nTest Metrics\\n------------------\")\n",
    "expected = {\n",
    "    \"beta\": 0.2882861014913346,\n",
    "    \"cindex\": 0.046803774122703735,\n",
    "    \"nc\": 2.6150343040385264,\n",
    "    \"dunn\": 0.05848053214719304,\n",
    "    \"db\": 0.8445815484442534,\n",
    "    \"sil\": 0.5032506980665507\n",
    "}\n",
    "for m in expected:\n",
    "    e = np.round(expected[m], 2)\n",
    "    a = getMetric(A_Iris_Test, C_Iris_Test, m)\n",
    "    a = np.round(a, 2) if not a is None else None\n",
    "    print(m + \":\\t\", \"ok\" if e == a else \"failed. Expected \" + str(e) + \" but saw \" + str(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kMeans(A, k, eps, mu):\n",
    "    A = pd.DataFrame(A, columns=['x', 'y'])\n",
    "    Dimensiones = A.shape[1]\n",
    "    centroides_min = np.min(A)\n",
    "    centroides_max = np.max(A)\n",
    "    centroides = []\n",
    "\n",
    "    def suma_errores_cuadrado(a,b):\n",
    "        error = np.square(np.sum((a-b)**2))\n",
    "        return error \n",
    "    \n",
    "    if(mu is not None) and (mu != 0):\n",
    "        if(len(mu) != k):\n",
    "            print('El número de centroides no coincide con el número de clusters')\n",
    "            return\n",
    "        centroidesdf = pd.DataFrame(mu)\n",
    "    else:\n",
    "        for centroid in range(k):\n",
    "            centroid = np.random.uniform(centroides_min, centroides_max, Dimensiones)\n",
    "            centroides.append(centroid)\n",
    "        centroidesdf = pd.DataFrame(centroides)\n",
    "    \n",
    "    errors = np.array([])\n",
    "    c = np.zeros(A.shape[0])\n",
    "    t = 0\n",
    "\n",
    "    def recalcular_centroides(A, c, k):\n",
    "        centroides_nuevos = []\n",
    "        for j in range(k):\n",
    "            if np.any(c == j):\n",
    "                nuevo_centroide = np.mean(A[c == j], axis=0)\n",
    "            else:\n",
    "                nuevo_centroide = np.random.rand(A.shape[1])\n",
    "            centroides_nuevos.append(nuevo_centroide)\n",
    "        return np.array(centroides_nuevos)\n",
    "        \n",
    "    while(True):\n",
    "        t += 1\n",
    "        for i in range(A.shape[0]):  \n",
    "            for centroid in range(centroidesdf.shape[0]):\n",
    "                error = suma_errores_cuadrado(A.iloc[i,:2].values, centroidesdf.iloc[centroid, :2])\n",
    "                errors = np.append(errors, error)\n",
    "                c[i] = np.argmin(errors)\n",
    "            errors = np.array([])\n",
    "        centroides_nuevos = recalcular_centroides(A, c, k)\n",
    "        \n",
    "        if np.sum(np.abs(centroidesdf.values - centroides_nuevos)) <= eps:\n",
    "            print(f'Converge en la iteración {t}')\n",
    "            break\n",
    "        centroidesdf = pd.DataFrame(centroides_nuevos)\n",
    "    \n",
    "    mu = []\n",
    "    for j in range(k):\n",
    "        if np.any(c == j):\n",
    "            mu_cluster = np.mean(A[c == j], axis=0)\n",
    "        mu.append(mu_cluster)\n",
    "    mu = np.array(mu)\n",
    "    return c, mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n",
    "\n",
    "def DBSCAN(D, epsilon, minpts):\n",
    "    \n",
    "    def find_distance(x):\n",
    "        return distance.squareform(distance.pdist(x))\n",
    "\n",
    "    def find_neighbors(x, epsilon):\n",
    "        return np.where(x <= epsilon)[0]\n",
    "\n",
    "    def expand_cluster(neighbors, cluster, labels, minpts):\n",
    "        for neighbor in neighbors:\n",
    "            if labels[neighbor] == -1:\n",
    "                labels[neighbor] = cluster\n",
    "                neighbor_neighbors = find_neighbors(dist_matrix[neighbor], epsilon)\n",
    "                if len(neighbor_neighbors) >= minpts:\n",
    "                    labels = expand_cluster(neighbor_neighbors, cluster, labels, minpts)\n",
    "        return labels\n",
    "\n",
    "    dist_matrix = find_distance(D)\n",
    "    cluster = -1\n",
    "    n_obs = D.shape[0]\n",
    "    labels = np.full(n_obs, -1)\n",
    "    for i in range(n_obs):\n",
    "        if labels[i] == -1:\n",
    "            neighbors = find_neighbors(dist_matrix[i], epsilon)\n",
    "            if len(neighbors) > minpts:\n",
    "                cluster += 1\n",
    "                labels[i] = cluster\n",
    "                labels = expand_cluster(neighbors, cluster, labels, minpts)\n",
    "            else:\n",
    "                labels[i] = -1  \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotMetrics(D, l=100, kmeans_eps=0.01, dbscan_configs=[(5, 0.5), (10, 0.5), (5, 1.0), (10, 1.0)]):\n",
    "    k_values = [2, 3, 4, 5]\n",
    "    metrics = ['Silhouette', 'CIndex', 'NormalizedCut', 'Dunn', 'DaviesBouldin', 'BetaCV']\n",
    "\n",
    "    kmeans_metrics = {metric: [] for metric in metrics}\n",
    "    dbscan_metrics = {metric: [[] for _ in dbscan_configs] for metric in metrics}\n",
    "\n",
    "    for k in k_values:\n",
    "        for _ in range(l):\n",
    "            _, labels = kMeans(D, k, kmeans_eps, None)\n",
    "            \n",
    "            kmeans_metrics['Silhouette'].append(getSilhouette(D, labels))\n",
    "            kmeans_metrics['CIndex'].append(getCIndex(D, labels))\n",
    "            kmeans_metrics['NormalizedCut'].append(getNormalizedCut(D, labels))\n",
    "            kmeans_metrics['Dunn'].append(getDunn(D, labels))\n",
    "            kmeans_metrics['DaviesBouldin'].append(getDaviesBouldin(D, labels))\n",
    "            kmeans_metrics['BetaCV'].append(getBetaCV(D, labels))\n",
    "    \n",
    "    for i, (minpts, eps) in enumerate(dbscan_configs):\n",
    "        labels = DBSCAN(D, eps, minpts)\n",
    "        for metric in metrics:\n",
    "            if metric == 'Silhouette':\n",
    "                dbscan_metrics[metric][i].append(getSilhouette(D, labels))\n",
    "            elif metric == 'CIndex':\n",
    "                dbscan_metrics[metric][i].append(getCIndex(D, labels))\n",
    "            elif metric == 'NormalizedCut':\n",
    "                dbscan_metrics[metric][i].append(getNormalizedCut(D, labels))\n",
    "            elif metric == 'Dunn':\n",
    "                dbscan_metrics[metric][i].append(getDunn(D, labels))\n",
    "            elif metric == 'DaviesBouldin':\n",
    "                dbscan_metrics[metric][i].append(getDaviesBouldin(D, labels))\n",
    "            elif metric == 'BetaCV':\n",
    "                dbscan_metrics[metric][i].append(getBetaCV(D, labels))\n",
    "\n",
    "    for metric in metrics:\n",
    "        plt.figure()\n",
    "        plt.title(metric)\n",
    "        plt.boxplot([kmeans_metrics[metric] for _ in range(len(k_values))], positions=k_values, widths=0.6, patch_artist=True, showfliers=False)\n",
    "        for i, (minpts, eps) in enumerate(dbscan_configs):\n",
    "            plt.axhline(y=np.mean(dbscan_metrics[metric][i]), color='r', linestyle='-', label=f'DBSCAN (minpts={minpts}, eps={eps})')\n",
    "        plt.xlabel('Number of Clusters (k)')\n",
    "        plt.ylabel(metric)\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

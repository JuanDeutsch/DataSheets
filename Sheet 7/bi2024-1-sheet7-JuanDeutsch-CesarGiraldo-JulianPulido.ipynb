{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eclat(db, minsup):\n",
    "    start_time=datetime.now()\n",
    "    time_format=\"%H:%M:%S:%f\"\n",
    "    temporal_items_list = []\n",
    "    for t in db:\n",
    "        temporal_items_list.extend(t)\n",
    "    temporal_items_list = list(sorted(set(temporal_items_list)))\n",
    "    item_list = temporal_items_list.copy()\n",
    "    item_list_transactions = {item: [] for item in temporal_items_list}\n",
    "    for transaction_index, t in enumerate(db):\n",
    "        for transaction_item in t:\n",
    "            item_list_transactions[(transaction_item)].append(transaction_index)\n",
    "    itemset_supports = [([item], item_list_transactions[item]) for item in item_list]\n",
    "    items_temporal=itemset_supports.copy()\n",
    "    temporal_items_list = item_list.copy()\n",
    "    \n",
    "    for itemset in itemset_supports:\n",
    "        if len(itemset[1]) < minsup:\n",
    "            temporal_items_list.remove(itemset[0][0])\n",
    "            items_temporal.remove(itemset)\n",
    "    itemset_supports=items_temporal.copy()\n",
    "    item_list = temporal_items_list.copy()\n",
    "    \n",
    "    final_supports_list=supportsNextLevel(itemset_supports,itemset_supports, item_list, minsup)\n",
    "    final_supports=[(item,len(transactions)) for item,transactions in final_supports_list]\n",
    "    final_time=datetime.now()\n",
    "    execution_time=(final_time-start_time)\n",
    "    print(f'Runtime: {execution_time}\\n    Start Time: {start_time.strftime(time_format)}\\n    Finish Time: {final_time.strftime(time_format)}')\n",
    "    return final_supports\n",
    "\n",
    "    \n",
    "def supportsNextLevel(total_supports, supports, items, minsup, first_time=True):\n",
    "    for index, itemset in enumerate(items[:-1]):\n",
    "        level_supports = []\n",
    "        itemset_derivate_list = []\n",
    "        items_to_combine = items[index+1:]\n",
    "        for other_itemset in items_to_combine:\n",
    "            if first_time:\n",
    "                new_itemset_support = findSupport(supports, [itemset], [other_itemset])\n",
    "                new_itemset_list = sorted(list(set([itemset, other_itemset])))\n",
    "            else:\n",
    "                new_list = []\n",
    "                new_list.extend(itemset)\n",
    "                new_list.extend(other_itemset)\n",
    "                new_itemset_support = findSupport(supports, itemset, other_itemset)\n",
    "                new_itemset_list = sorted(list(set(new_list)))\n",
    "            if len(new_itemset_support) >= minsup:\n",
    "                level_supports.append((new_itemset_list, new_itemset_support))\n",
    "                itemset_derivate_list.append(new_itemset_list)   \n",
    "        total_supports.extend(level_supports)\n",
    "        if len(level_supports) > 1 and level_supports:\n",
    "            supportsNextLevel(total_supports, level_supports, itemset_derivate_list, minsup, False)\n",
    "    if first_time:\n",
    "        return total_supports\n",
    "\n",
    "\n",
    "def findSupport(supports, first_itemset, second_itemset):\n",
    "    for support in supports:\n",
    "        if first_itemset == support[0]:\n",
    "            first_support = support[1]\n",
    "        if second_itemset == support[0]:\n",
    "            second_support = support[1]\n",
    "    return list(set(first_support) & set(second_support))\n",
    "\n",
    "def getStrongRulesFromFrequentSets(fsets, minconf):\n",
    "   strong_rules = []\n",
    "   fsets_sets = [fset[0] for fset in fsets]\n",
    "   fsets_supports = [fset[1] for fset in fsets]\n",
    "\n",
    "   for i, set in enumerate(fsets_sets):\n",
    "        if len(set) >= 2:\n",
    "           A = subsets_non_empty(set)\n",
    "           while A:\n",
    "               X = max(A, key=lambda x: fsets_supports[fsets_sets.index(x)])\n",
    "               A.remove(X)\n",
    "               index = fsets_sets.index(X)\n",
    "               sup_z = fsets_supports[i]\n",
    "               sup_x = fsets_supports[index]\n",
    "               conf = sup_z / sup_x\n",
    "               if conf >= minconf:\n",
    "                   Y = set.copy()\n",
    "                   for x in X:\n",
    "                       Y.remove(x)\n",
    "                   strong_rules.append((X, Y, fsets_supports[i], conf))\n",
    "               else: \n",
    "                  for w in X:\n",
    "                     if w in A:\n",
    "                        A.remove(x)                \n",
    "   return strong_rules\n",
    "\n",
    "def subsets_non_empty(Z):\n",
    "   all_subsets = chain.from_iterable(combinations(Z,r) for r in range(1, len(Z) + 1)) \n",
    "   non_empty_subsets = [sorted(subset) for subset in all_subsets if subset]\n",
    "   non_empty_subsets.sort(key=lambda x: (len(x), x))\n",
    "   non_empty_subsets.pop(-1)\n",
    "   return non_empty_subsets\n",
    "\n",
    "def getStrongRulesForDatabase(db, minsup, minconf):\n",
    "  fsets = eclat(db, minsup)\n",
    "  strong_rules = getStrongRulesFromFrequentSets(fsets, minconf)\n",
    "  return strong_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sup(D, X, Y=None):\n",
    "    supp = 0\n",
    "    if Y is None:\n",
    "        for transaction in D:\n",
    "            if all(item in transaction for item in X):\n",
    "                supp += 1\n",
    "    else:\n",
    "        for transaction in D:\n",
    "            if all(item in transaction for item in X) and all(item in transaction for item in Y):\n",
    "                supp += 1\n",
    "    return supp\n",
    "\n",
    "def conf(D, X, Y):\n",
    "    return sup(D, X, Y) / sup(D, X)\n",
    "\n",
    "def lift(D, X, Y=None):\n",
    "    if Y is None:\n",
    "        Y = X.copy()\n",
    "    supports = [sum(all(item in transaction for item in items) for transaction in D) for items in (X, Y, X + Y)]\n",
    "    if 0 in (r_support := [sup / len(D) for sup in supports]):\n",
    "        return None\n",
    "    return r_support[2] / (r_support[0] * r_support[1])\n",
    "\n",
    "def leverage(D, X, Y):\n",
    "    supports = [sum(all(item in transaction for item in items) for transaction in D) for items in (X, Y, X + Y)]\n",
    "    final_leverage = supports[2] / len(D) - (supports[0] / len(D)) * (supports[1] / len(D))\n",
    "    return final_leverage\n",
    "\n",
    "def jaccard(D, X, Y):\n",
    "    return sup(D, X, Y) / (sup(D, X) + sup(D, Y) - sup(D, X, Y))\n",
    "\n",
    "def conviction(D, X, Y):\n",
    "    support_y = sum(all(item in transaction for item in Y) for transaction in D) / len(D)\n",
    "    confidence_xy = conf(D, X, Y)\n",
    "    if confidence_xy >= 1:\n",
    "        return None\n",
    "    return (1 - support_y) / (1 - confidence_xy)\n",
    "\n",
    "def oddsRatio(D, X, Y):\n",
    "    supports = {(False, False): 0, (False, True): 0, (True, False): 0, (True, True): 0}\n",
    "    for transaction in D:\n",
    "        supports[(all(item in transaction for item in X), all(item in transaction for item in Y))] += 1\n",
    "    final_odds_ratio = ((supports[(True, True)] + 1) * (supports[(False, False)] + 1)) / ((supports[(False, True)] + 1) * (supports[(True, False)] + 1))\n",
    "    return final_odds_ratio\n",
    "\n",
    "def imp(D, X, Y):\n",
    "    if len(X) < 2:\n",
    "        return 0\n",
    "    conf_xy = conf(D, X, Y)\n",
    "    w_conf = [conf(D, W, Y) for W in X]\n",
    "    return conf_xy - max(w_conf) if w_conf else 0\n",
    "\n",
    "def getRuleMetric(D,X,Y,metric):\n",
    "    if metric == \"sup\":\n",
    "        return sup(D,X,Y)\n",
    "    elif metric == \"conf\":\n",
    "        return conf(D,X,Y)\n",
    "    elif metric == \"lift\":\n",
    "        return lift(D,X,Y)\n",
    "    elif metric == \"leverage\":\n",
    "        return leverage(D,X,Y)\n",
    "    elif metric == \"jaccard\":\n",
    "        return jaccard(D,X,Y)\n",
    "    elif metric == \"conviction\":\n",
    "        return conviction(D,X,Y)\n",
    "    elif metric == \"oddsratio\":\n",
    "        return oddsRatio(D,X,Y)\n",
    "    elif metric == \"imp\":\n",
    "        return imp(D,X,Y)\n",
    "    else:\n",
    "        return \"metrica invalida\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterProductiveRules(D, R):\n",
    "    productive_rules = []\n",
    "    for rule in R:\n",
    "        X, Y, sup_XY, conf_XY = rule\n",
    "        if conf_XY > 0:\n",
    "            productive_rules.append(rule)\n",
    "    return productive_rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

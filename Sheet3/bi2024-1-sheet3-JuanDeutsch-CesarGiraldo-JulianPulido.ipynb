{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juan Manuel Deutsch, Cesar Felipe Giraldo, Julian Felipe Pulido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio tenemos $X$ siendo la matriz base y $Σ$ como la matriz de covarianza de $X$\n",
    "\n",
    "Tambien tenemos los componentes principales $u_1, u_2,...,u_n$, que son los autovectores o vectores propios de $Σ$ que tienen varianzas asociadas $u_i^TΣu_i$, donde $u_i^T$ es la transpuesta del vector propio $u_i$\n",
    "\n",
    "Ahora tendremos una tranformación lineal de los datos $X$, siendo $AX$ donde $A$ es una transformación $m x m$\n",
    "\n",
    "Ahora con la matriz transformada tenemos la matriz de covarianza transformada $AΣA^T$ cuyos componentes principales estan dados por $v_1, v_2,...,v_n$ estos siendo los autovectores cuyas varianza asociadas estan dadas por $v_i^TAΣA^Tv_i$\n",
    "\n",
    "Teniendo en cuenta que necesitamos demostrar los componentes principales y como cambian tenemos con relacion a $AX$ y $X$\n",
    "\n",
    "$u_1$ siendo componente principal cuya varianza asociada es $u_i^TΣu_i$ y siendo $v_1$ el componente principal cuya varianza asociada es $v_i^TAΣA^Tv_i$\n",
    "\n",
    "Teniendo en cuenta que $u_1$ y $v_1$ estan relacionados por una transformación lineal tenemos que $v_1 = Tu_1$ para una matriz T\n",
    "\n",
    "Ahora, se puede escribir la varianza asociada de $v_1$ como:\n",
    "\n",
    "$$v_1^TAΣA^Tv_1 = (Tu_1)^TAΣA^T(Tu_1) = u_1^TT^TAΣA^TTu_1$$\n",
    "\n",
    "Dado que $T$ es una matriz de transformacion lineal, $T^TAΣA^TT$ es otra matriz de covarianza $Σ'$\n",
    "\n",
    "Por lo tanto ahora tenemos:\n",
    "\n",
    "$$v_1^TAΣA^Tv_1 = u_1^TΣ'u_1$$\n",
    "\n",
    "Concluyendo con esta demostración, tenemos que la varianza asociada $v_1$ depende de la matriz de covarianza $Σ'$ que es una version transformada de la matriz de covarianza original $Σ$, por lo cual, $Σ'$ es diferente a $Σ$, entonces la varianza asociada a estos van a ser diferentes, por lo que un valor propio esta ligado conjunto de datos original y el otro valor propio esta ligado al conjunto transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta demostracion tenemos $D$, como una matriz $f x c$ donde $f$ son filas y $c$ son columnas, ademas de $D'$ que es la matriz transformada con una transformación afin a una o mas columnas\n",
    "\n",
    "Iniciando calculamos la matriz de correlación $corr(D)$\n",
    "$$corr(D) = 1/n (D - D_u)^T(D - D_u)$$\n",
    "Donde $D_u$ es la media de cada columna de $D$\n",
    "De acuerdo a eso se los componentes principales por medio de $corr(D)$\n",
    "\n",
    "Ahora realizamos el mismo proceso con la tranformación afin, que seria del siguiente modo:\n",
    "\n",
    "$$D' = A*D+b$$\n",
    "\n",
    "Donde $A$ es la transformación lineal y $b$ es el desplazamiento\n",
    "\n",
    "Ahora calculamos la correlacion \n",
    "\n",
    "$$corr(D') = 1/n (D' - D'_u)^T(D' - D'_u)$$\n",
    "\n",
    "Donde ahora $D'_u$ es la media de la matriz transformada, donde las columnas de $D'$ se ven afectadas por la transformación afin\n",
    "\n",
    "Pero debemos tener en cuenta que para la covarianza los efectos de una transformación afin se dan de la siguiente forma:\n",
    "\n",
    "$$cov(D') = A^Tcov(D)A$$\n",
    "\n",
    "No obstante, estamos tratando es con matrices de correlación, las cuales son versiones escaladas de las matrices de covariaza, por lo cual la matriz de covarianza tambien afecta a la matriz de correlación con la misma transformación afin\n",
    "\n",
    "Por lo cual los autovectores o vectores propios de $corr(D')$ son los mismos que $corr(D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[[-0.81649658  0.57735027]\n",
      " [ 0.40824829  0.57735027]\n",
      " [ 0.40824829  0.57735027]]\n",
      "[[-2.22044605e-16 -1.03923048e+01]\n",
      " [-1.11022302e-16 -5.19615242e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00]\n",
      " [ 1.11022302e-16  5.19615242e+00]\n",
      " [ 2.22044605e-16  1.03923048e+01]]\n",
      "67.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def PCA(D, red):\n",
    "\n",
    "    mu = np.mean(D, axis=0)\n",
    "\n",
    "    Z = D - mu\n",
    "    \n",
    "    cov_matrix = np.cov(Z, rowvar=False, bias=False)\n",
    "    \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    if red < 1:\n",
    "\n",
    "        total_variance = np.sum(eigenvalues)\n",
    "        variance_top = red * total_variance\n",
    "        \n",
    "        cumulative_variance = 0\n",
    "        r = 0\n",
    "        for i in range(len(eigenvalues)):\n",
    "            cumulative_variance += eigenvalues[i]\n",
    "            if cumulative_variance >= variance_top:\n",
    "                r = i + 1\n",
    "            break\n",
    "    else:\n",
    "\n",
    "        r = red\n",
    "    \n",
    "    print(r)\n",
    "  \n",
    "    top_eigenvectors = eigenvectors[:, :r]\n",
    "\n",
    "    print(top_eigenvectors)\n",
    "    \n",
    "    A = np.dot(Z, top_eigenvectors)\n",
    "    \n",
    "    v = np.sum(eigenvalues[:r])\n",
    "    \n",
    "    return A, v\n",
    "\n",
    "#Prueba\n",
    "\n",
    "D = np.array([[1, 2, 3],\n",
    "               [4, 5, 6],\n",
    "               [7, 8, 9],\n",
    "               [10, 11, 12],\n",
    "               [13, 14, 15]])\n",
    "\n",
    "# Aplicamos PCA para reducir a 2 dimensiones conservando el 50% de la varianza\n",
    "A, variance = PCA(D, 0.5)\n",
    "print(A)\n",
    "print(variance)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JULIAN PULIDO CASTRO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\Users\\JULIAN PULIDO CASTRO\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\lib\\function_base.py:2898: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n",
      "C:\\Users\\JULIAN PULIDO CASTRO\\AppData\\Local\\Temp\\ipykernel_9988\\4089043293.py:38: RuntimeWarning: invalid value encountered in divide\n",
      "  cor_np = cov_np / np.outer(desv, desv)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dataset  Tiempo getStats  Tiempo Numpy\n",
      "0              iris         0.086769      0.118026\n",
      "1  baseball_numeric         0.002998      0.001001\n",
      "2            fabert         0.210050      0.088030\n",
      "3            amazon         3.791638      4.642221\n"
     ]
    }
   ],
   "source": [
    "# A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def getStats(A):\n",
    "    \n",
    "    mu = np.mean(A, axis=0)\n",
    "    cov = np.cov(A, rowvar=False)\n",
    "    cor = np.corrcoef(A, rowvar=False)\n",
    "    return mu, cov, cor\n",
    "\n",
    "iris_data = pd.read_csv('iris.csv')\n",
    "baseball_data = pd.read_csv('baseball_numeric.csv')\n",
    "fabert_data = pd.read_csv('fabert.csv')\n",
    "amazon_data = pd.read_csv('amazon.csv')\n",
    "\n",
    "datasets = {'iris': iris_data, 'baseball_numeric': baseball_data, 'fabert': fabert_data, 'amazon': amazon_data}\n",
    "results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "\n",
    "    # Excluir las columnas no numéricas\n",
    "    numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "    dataset_numeric = dataset[numeric_cols]\n",
    "    \n",
    "    # Convertir el DataFrame a un array de NumPy\n",
    "    A = dataset_numeric.values.astype(float)  # Convertir los datos a tipo float\n",
    "    \n",
    "    # Medir el tiempo de ejecución de getStats\n",
    "    start_time_getStats = time.time()\n",
    "    mu, cov, cor = getStats(A)\n",
    "    getStats_time = time.time() - start_time_getStats\n",
    "    \n",
    "    # Medir el tiempo de ejecución de NumPy para calcular la matriz de correlación\n",
    "    start_time_np = time.time()\n",
    "    cov_np = np.cov(A, rowvar=False, bias=False)\n",
    "    desv = np.sqrt(np.diag(cov_np))\n",
    "    cor_np = cov_np / np.outer(desv, desv)\n",
    "    np_time = time.time() - start_time_np\n",
    "    \n",
    "    results.append({'Dataset': dataset_name, 'Tiempo getStats': getStats_time, 'Tiempo Numpy': np_time})\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dataset  Dimensiones     Varianza total absoluta  \\\n",
      "0              iris            4      4.569291+    0.000000j   \n",
      "1  baseball_numeric            9  17411.999147+    0.000000j   \n",
      "2            fabert            9      3.073882+    0.000000j   \n",
      "3            amazon            9   8868.256627+    0.000000j   \n",
      "\n",
      "   Varianza Total Relativa  \n",
      "0       1.000000+0.000000j  \n",
      "1       0.999947+0.000000j  \n",
      "2       0.538146+0.000000j  \n",
      "3       0.656720+0.000000j  \n"
     ]
    }
   ],
   "source": [
    "#B\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datasets = {'iris': iris_data, 'baseball_numeric': baseball_data, 'fabert': fabert_data, 'amazon': amazon_data}\n",
    "results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "\n",
    "    numeric_dataset = dataset.select_dtypes(include=[np.number])\n",
    "    A = numeric_dataset.values.astype(float)   \n",
    "\n",
    "    reduced_data, variance = PCA(A, 9)\n",
    "    \n",
    "    total_variance_original = np.sum(np.linalg.eigvals(np.cov(A, rowvar=False)))\n",
    "    relative_total_variance = variance / total_variance_original\n",
    "    \n",
    "    results.append({'Dataset': dataset_name, 'Dimensiones': reduced_data.shape[1], 'Varianza total absoluta': variance, 'Varianza Total Relativa': relative_total_variance})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dataset         Varianza (1D)  Varianza Relativa (1D)  \\\n",
      "0              iris      4.225+    0.000j            0.925+0.000j   \n",
      "1  baseball_numeric  11828.850+    0.000j            0.679+0.000j   \n",
      "2            fabert      2.928+    0.000j            0.513+0.000j   \n",
      "3            amazon   7324.483+    0.000j            0.542+0.000j   \n",
      "\n",
      "          Varianza (2D)  Varianza Relativa(2D)         Varianza (3D)  \\\n",
      "0      4.467+    0.000j           0.978+0.000j      4.546+    0.000j   \n",
      "1  17228.156+    0.000j           0.989+0.000j  17391.761+    0.000j   \n",
      "2      2.953+    0.000j           0.517+0.000j      2.975+    0.000j   \n",
      "3   7745.115+    0.000j           0.574+0.000j   7998.002+    0.000j   \n",
      "\n",
      "   Varianza Relativa (3D)  \n",
      "0            0.995+0.000j  \n",
      "1            0.999+0.000j  \n",
      "2            0.521+0.000j  \n",
      "3            0.592+0.000j  \n"
     ]
    }
   ],
   "source": [
    "#C\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "datasets = {'iris': iris_data, 'baseball_numeric': baseball_data, 'fabert': fabert_data, 'amazon': amazon_data}\n",
    "results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "\n",
    "    numeric_dataset = dataset.select_dtypes(include=[np.number])\n",
    "    \n",
    "    X = numeric_dataset.values.astype(float)\n",
    "    \n",
    "    variances = []\n",
    "    relative_variances = []\n",
    "    \n",
    "    for n_components in [1, 2, 3]:\n",
    "\n",
    "        reduced_data, total_variance = PCA(X, n_components)\n",
    "        relative_total_variance = total_variance / np.sum(np.linalg.eig(np.cov(X, rowvar=False, bias=False))[0])\n",
    "        \n",
    "        variances.append(total_variance)\n",
    "        relative_variances.append(relative_total_variance)\n",
    "    \n",
    "    results.append({'Dataset': dataset_name, 'Varianza (1D)': variances[0], 'Varianza Relativa (1D)': relative_variances[0],\n",
    "                    'Varianza (2D)': variances[1], 'Varianza Relativa(2D)': relative_variances[1],\n",
    "                    'Varianza (3D)': variances[2], 'Varianza Relativa (3D)': relative_variances[2]})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.round(3)  \n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juan Manuel Deutsch, Cesar Felipe Giraldo, Julian Felipe Pulido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio tenemos $X$ siendo la matriz base y $Σ$ como la matriz de covarianza de $X$\n",
    "\n",
    "Tambien tenemos los componentes principales $u_1, u_2,...,u_n$, que son los autovectores o vectores propios de $Σ$ que tienen varianzas asociadas $u_i^TΣu_i$, donde $u_i^T$ es la transpuesta del vector propio $u_i$\n",
    "\n",
    "Ahora tendremos una tranformación lineal de los datos $X$, siendo $AX$ donde $A$ es una transformación $m x m$\n",
    "\n",
    "Ahora con la matriz transformada tenemos la matriz de covarianza transformada $AΣA^T$ cuyos componentes principales estan dados por $v_1, v_2,...,v_n$ estos siendo los autovectores cuyas varianza asociadas estan dadas por $v_i^TAΣA^Tv_i$\n",
    "\n",
    "Teniendo en cuenta que necesitamos demostrar los componentes principales y como cambian tenemos con relacion a $AX$ y $X$\n",
    "\n",
    "$u_1$ siendo componente principal cuya varianza asociada es $u_i^TΣu_i$ y siendo $v_1$ el componente principal cuya varianza asociada es $v_i^TAΣA^Tv_i$\n",
    "\n",
    "Teniendo en cuenta que $u_1$ y $v_1$ estan relacionados por una transformación lineal tenemos que $v_1 = Tu_1$ para una matriz T\n",
    "\n",
    "Ahora, se puede escribir la varianza asociada de $v_1$ como:\n",
    "\n",
    "$$v_1^TAΣA^Tv_1 = (Tu_1)^TAΣA^T(Tu_1) = u_1^TT^TAΣA^TTu_1$$\n",
    "\n",
    "Dado que $T$ es una matriz de transformacion lineal, $T^TAΣA^TT$ es otra matriz de covarianza $Σ'$\n",
    "\n",
    "Por lo tanto ahora tenemos:\n",
    "\n",
    "$$v_1^TAΣA^Tv_1 = u_1^TΣ'u_1$$\n",
    "\n",
    "Concluyendo con esta demostración, tenemos que la varianza asociada $v_1$ depende de la matriz de covarianza $Σ'$ que es una version transformada de la matriz de covarianza original $Σ$, por lo cual, $Σ'$ es diferente a $Σ$, entonces la varianza asociada a estos van a ser diferentes, por lo que un valor propio esta ligado conjunto de datos original y el otro valor propio esta ligado al conjunto transformado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta demostracion tenemos $D$, como una matriz $f x c$ donde $f$ son filas y $c$ son columnas, ademas de $D'$ que es la matriz transformada con una transformación afin a una o mas columnas\n",
    "\n",
    "Iniciando calculamos la matriz de correlación $corr(D)$\n",
    "$$corr(D) = 1/n (D - D_u)^T(D - D_u)$$\n",
    "Donde $D_u$ es la media de cada columna de $D$\n",
    "De acuerdo a eso se los componentes principales por medio de $corr(D)$\n",
    "\n",
    "Ahora realizamos el mismo proceso con la tranformación afin, que seria del siguiente modo:\n",
    "\n",
    "$$D' = A*D+b$$\n",
    "\n",
    "Donde $A$ es la transformación lineal y $b$ es el desplazamiento\n",
    "\n",
    "Ahora calculamos la correlacion \n",
    "\n",
    "$$corr(D') = 1/n (D' - D'_u)^T(D' - D'_u)$$\n",
    "\n",
    "Donde ahora $D'_u$ es la media de la matriz transformada, donde las columnas de $D'$ se ven afectadas por la transformación afin\n",
    "\n",
    "Pero debemos tener en cuenta que para la covarianza los efectos de una transformación afin se dan de la siguiente forma:\n",
    "\n",
    "$$cov(D') = A^Tcov(D)A$$\n",
    "\n",
    "No obstante, estamos tratando es con matrices de correlación, las cuales son versiones escaladas de las matrices de covariaza, por lo cual la matriz de covarianza tambien afecta a la matriz de correlación con la misma transformación afin\n",
    "\n",
    "Por lo cual los autovectores o vectores propios de $corr(D')$ son los mismos que $corr(D)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos reducidos A:\n",
      " [[-2.22383293  6.62077922 -0.9864382   0.03164106]\n",
      " [-5.55127862 -4.7594466   0.5427392   2.28080035]\n",
      " [ 0.55058985 -0.98729531 -1.77065664 -0.80993837]\n",
      " [ 3.68276669  1.36321497 -3.73620713  3.34999953]\n",
      " [-4.37500465  2.74874794  3.09709231  0.07380571]\n",
      " [ 2.10915442  0.84383508  2.99845749 -2.2964254 ]\n",
      " [ 3.03064114  0.41677691  2.57421906  1.72366106]\n",
      " [ 6.92241058 -2.45359706  1.51927006 -0.63565965]\n",
      " [-1.04675051 -0.9551932  -4.22672217 -3.08842427]\n",
      " [-3.09869596 -2.83782195 -0.01175398 -0.62946002]]\n",
      "\n",
      "La varianza de la matriz A: 37.02020528711315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "def PCA(D, red):\n",
    "    mu = np.mean(D, axis=0)\n",
    "    Z = D - mu\n",
    "    cov_matrix = np.cov(Z, rowvar=False, bias=False)\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "\n",
    "    topEigenvalues = eigenvalues[sorted_indices]\n",
    "    topEigenVector = eigenvectors[:,sorted_indices]\n",
    "    cumvariance = np.cumsum(topEigenvalues)\n",
    "\n",
    "    if red < 1:\n",
    "        total_variance = np.sum(topEigenvalues)\n",
    "        cumvariance = np.cumsum(topEigenvalues)\n",
    "        variance_top = red * total_variance\n",
    "        numdims = np.argmax(cumvariance >= variance_top) + 1\n",
    "        \n",
    "    else:\n",
    "        numdims = red\n",
    "    top_eigenvectors = topEigenVector[:, :numdims] \n",
    "    total_variance = np.sum(topEigenvalues[:numdims]) \n",
    "    variance = total_variance / np.sum(topEigenvalues)\n",
    "    A = np.dot(Z, top_eigenvectors)\n",
    "\n",
    "\n",
    "    v = np.sum(topEigenvalues[:numdims])\n",
    "\n",
    "    \n",
    "    return A, v\n",
    "\n",
    "D = np.array([[4, 1, 0, 9, 8],\n",
    " [9, 9, 1, 6, 1],\n",
    " [4, 5, 3, 3, 5],\n",
    " [6, 2, 7, 3, 8],\n",
    " [5, 1, 0, 8, 1],\n",
    " [0, 4, 4, 6, 3],\n",
    " [3, 3, 7, 6, 3],\n",
    " [0, 6, 9, 3, 4],\n",
    " [4, 5, 0, 1, 6],\n",
    " [6, 5, 1, 3, 1]])\n",
    "\n",
    "A, variance = PCA(D, 4)\n",
    "print(f'Datos reducidos A:\\n {A}\\n')\n",
    "print(f'La varianza de la matriz A: {variance}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Preparación de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/4b01rf9j7cl6mcd3652m260w0000gn/T/ipykernel_87687/3708956956.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "iris_data = pd.read_csv('iris.csv')\n",
    "baseball_data = pd.read_csv('baseball_numeric.csv')\n",
    "fabert_data = pd.read_csv('fabert.csv')\n",
    "amazon_data = pd.read_csv('amazon.csv')\n",
    "\n",
    "\n",
    "adf2 = amazon_data.drop('Class', axis=1).values\n",
    "fdf2 = fabert_data.values\n",
    "idf2 = iris_data.drop('species', axis=1).values\n",
    "bndf = baseball_data.values\n",
    "\n",
    "datasets = [bndf, fdf2, idf2]\n",
    "data_dict = ['Baseball Dataset', 'Fabert Dataset', 'Iris Dataset']\n",
    "\n",
    "datasetsDictionary = {'iris': iris_data, 'baseball_numeric': baseball_data, 'fabert': fabert_data}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mu, cov, cor\n\u001b[1;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset_name, dataset \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m     17\u001b[0m     numeric_cols \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     18\u001b[0m     dataset_numeric \u001b[38;5;241m=\u001b[39m dataset[numeric_cols]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def getStats(A):\n",
    "\n",
    "        mu = list(sum(row)/len(row) for row in zip(*A))\n",
    "\n",
    "        n = A.shape[0]\n",
    "        cov_mu = A - mu\n",
    "        cov = np.dot(cov_mu.T, cov_mu) / (n)\n",
    " \n",
    "        desv = np.sqrt(np.diag(cov))\n",
    "        cor = cov / np.outer(desv, desv)\n",
    "\n",
    "        return mu, cov, cor\n",
    "results = []\n",
    "\n",
    "for dataset_name, dataset in datasets.items():\n",
    "\n",
    "    numeric_cols = dataset.select_dtypes(include=[np.number]).columns\n",
    "    dataset_numeric = dataset[numeric_cols]\n",
    "    \n",
    "    A = dataset_numeric.values.astype(float)  \n",
    "    \n",
    "    start_time_getStats = time.time()\n",
    "    mu, cov, cor = getStats(A)\n",
    "    getStats_time = time.time() - start_time_getStats\n",
    "    \n",
    "    start_time_np = time.time()\n",
    "    cov_np = np.cov(A, rowvar=False, bias=False)\n",
    "    desv = np.sqrt(np.diag(cov_np))\n",
    "    cor_np = cov_np / np.outer(desv, desv)\n",
    "    np_time = time.time() - start_time_np\n",
    "    \n",
    "    results.append({'Dataset': dataset_name, 'Tiempo getStats': getStats_time, 'Tiempo Numpy': np_time})\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nuestra función</th>\n",
       "      <th>Función de numpy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amazon Dataset</th>\n",
       "      <td>5.521663</td>\n",
       "      <td>4.341354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseball Dataset</th>\n",
       "      <td>0.006432</td>\n",
       "      <td>0.000730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fabert Dataset</th>\n",
       "      <td>0.805461</td>\n",
       "      <td>0.299242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Iris Dataset</th>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Nuestra función  Función de numpy\n",
       "Amazon Dataset           5.521663          4.341354\n",
       "Baseball Dataset         0.006432          0.000730\n",
       "Fabert Dataset           0.805461          0.299242\n",
       "Iris Dataset             0.000289          0.000200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import timeit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "def getStats(A):\n",
    "    start = timeit.default_timer()\n",
    "    #Media\n",
    "    mu = list(sum(row)/len(row) for row in zip(*A))\n",
    "    #Covarianza\n",
    "    n = A.shape[0]\n",
    "    cov_mu = A - mu\n",
    "    cov = np.dot(cov_mu.T, cov_mu) / (n)\n",
    "    return mu, cov, timeit.default_timer() - start\n",
    "\n",
    "def getStatsNumpy(A):\n",
    "    start = timeit.default_timer()\n",
    "    mu = np.mean(A, axis=0)\n",
    "    cov = np.cov(A, rowvar=False, bias=False)\n",
    "    return mu, cov, timeit.default_timer() - start\n",
    "\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    combined_results = np.array([getStats(dataset)[2], getStatsNumpy(dataset)[2]]) \n",
    "    all_results.append(combined_results)\n",
    "\n",
    "df = pd.DataFrame(all_results, index = data_dict, columns=['Nuestra función', 'Función de numpy'])\n",
    "display(df) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dataset  Dimensiones  Varianza total absoluta  \\\n",
      "0              iris            1                 4.224841   \n",
      "1  baseball_numeric            2             17228.155686   \n",
      "2            fabert          391                 5.141834   \n",
      "\n",
      "   Varianza Total Relativa  \n",
      "0                 0.924616  \n",
      "1                 0.989389  \n",
      "2                 0.900184  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "results = []\n",
    "\n",
    "for dataset_name, dataset in datasetsDictionary.items():\n",
    "    \n",
    "    numeric_dataset = dataset.select_dtypes(include=[np.number])\n",
    "    A = numeric_dataset.values.astype(float)\n",
    "\n",
    "    reduced_data, variance = PCA(A, 0.9)\n",
    "    \n",
    "    total_variance_original = np.sum(np.linalg.eigvals(np.cov(A, rowvar=False)))\n",
    "    relative_total_variance = variance / total_variance_original\n",
    "    \n",
    "    results.append({'Dataset': dataset_name, 'Dimensiones': reduced_data.shape[1], 'Varianza total absoluta': variance, 'Varianza Total Relativa': relative_total_variance})\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Dataset  Varianza (1D)  Varianza Relativa (1D)  Varianza (2D)  \\\n",
      "0              iris          4.225                   0.925          4.467   \n",
      "1  baseball_numeric      11828.850                   0.679      17228.156   \n",
      "2            fabert          2.928                   0.513          2.953   \n",
      "\n",
      "   Varianza Relativa(2D)  Varianza (3D)  Varianza Relativa (3D)  \n",
      "0                  0.978          4.546                   0.995  \n",
      "1                  0.989      17391.761                   0.999  \n",
      "2                  0.517          2.975                   0.521  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = []\n",
    "for dataset_name, dataset in datasetsDictionary.items():\n",
    "\n",
    "    numeric_dataset = dataset.select_dtypes(include=[np.number])\n",
    "    \n",
    "    X = numeric_dataset.values.astype(float)\n",
    "    \n",
    "    variances = []\n",
    "    relative_variances = []\n",
    "    \n",
    "    for n_components in [1, 2, 3]:\n",
    "\n",
    "        reduced_data, total_variance = PCA(X, n_components)\n",
    "        relative_total_variance = total_variance / np.sum(np.linalg.eig(np.cov(X, rowvar=False, bias=False))[0])\n",
    "        \n",
    "        variances.append(total_variance)\n",
    "        relative_variances.append(relative_total_variance)\n",
    "    \n",
    "    results.append({'Dataset': dataset_name, 'Varianza (1D)': variances[0], 'Varianza Relativa (1D)': relative_variances[0],\n",
    "                    'Varianza (2D)': variances[1], 'Varianza Relativa(2D)': relative_variances[1],\n",
    "                    'Varianza (3D)': variances[2], 'Varianza Relativa (3D)': relative_variances[2]})\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df = results_df.round(3)  \n",
    "print(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
